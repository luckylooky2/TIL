- 이 장에서는 **비례 배분(Proportional Share) 스케줄러**, 혹은 **공정 배분(fair share)**이라고도 하는 유형의 스케줄러에 대해 다루도록 하겠다
- 이전 장까지 다루었던 스케줄링 방법과는 목적이 다르다. *MLFQ는 반환 시간이나 응답 시간을 최적화*하는 스케줄러이다. 반면 이 장에서 다룰 스케줄러는 *각 작업에게 CPU의 일정 비율을 보장*하는 것이 목적이다
- 추첨 스케줄링(lottery scheduling) : 비례 배분 스케줄링
  - 다음 실행될 프로세스를 추첨을 통해 결정한다. 더 자주 수행되어야 하는 프로세스는 당첨 기회를 더 많이 준다
  - 어떻게 CPU를 정해진 비율로 배분할 수 있는가?
  - 특정 비율로 CPU를 배분하는 스케줄러를 어떻게 설계할 수 있는가?

### 기본 개념 : 추첨권이 당신의 지분이다

- 추첨권(티켓)이라는 기본적인 개념이 추첨 스케줄링의 근간을 이룬다
- 추첨권은 **특정 자원에 대한 프로세스에게 (또는 사용자 또는 그 무엇이든) 할당될 몫(지분)**을 나타낸다
- 즉, 특정 프로세스의 몫(비율) = 해당 프로세스가 소유한 티켓 개수 / 전체 티켓
- 동작 방식
  - 타임 슬라이스가 끝날 때마다 확률 기반으로 추첨한다
  - 스케줄러는 추첨권의 총 개수를 파악한다
  - 스케줄러는 추첨권을 뽑는다
  - 추첨권은 0 에서 99의 숫자다
  - 뽑힌 추첨권 값에 따라 다음에 실행될 프로세스가 결정된다
  - 스케줄러는 당첨된 프로세스를 실행한다
  - e.g.
    - 63 85 70 39 76 17 29 41 36 39 10 99 68 83 63 62 43 0 49
    - A B A A B A A A A A A B A B A A A A A
- 이 예에서 볼 수 있듯이 무작위성은 원하는 비율을 정확히 보장하지는 않는다. 하지만, 두 작업이 장시간 실행될수록, 원하는 비율을 달성할 가능성이 높아진다.
- 무작위 기법의 장점
  - 1. LRU 교체 알고리즘은 반복되는 순차적인 접근 패턴을 보이는 오버헤드에 대해서는 최악의 성능을 보이지만, 무작위 방식에서는 그러한 최악의 경우가 발생하지 않는다
  - 2. 매우 가볍다 : 관리해야 할 상태 정보가 거의 없기 때문이다
  - 3. 매우 빠르다 : 난수 발생 시간이 빠르기만 하면 결정 역시 빠르게 된다

### 추첨 기법

- 1. 추첨권 화폐(ticket currency)

  - 사용자가 받은 추첨권(global currency)을 자신의 화폐 가치(local currency)로 추첨권을 자유롭게 할당할 수 있도록 허용한다

  !["9-1"](9-1.png)

  - 사용자 A, B가 각각 100장의 추첨권을 받았다고 가정하자
  - 계산을 통해 전체 기준이 되는 추첨권으로 변환된다
  - 추첨은 전체 기준이 되는 추첨권의 양 (총 200장)을 기준으로 추첨한다

- 2. 추첨권 양도(ticket transfer)

  - 양도를 통하여 프로세스는 일시적으로 추첨권을 다른 프로세스에게 넘겨줄 수 있다
  - 클라이언트/서버 환경에서 특히 유용하다
  - 클라이언트 프로세스는 서버에게 메시지를 보내 자신을 대신해 특정 작업을 해달라고 요청한다
  - 작업이 빨리 완료될 수 있도록 _클라이언트는 서버에게 추첨권을 전달하고_ 서버가 자신의 요청을 수행하는 동안 서버의 성능을 극대화하려고 한다
  - _요청을 완수하면 서버는 추첨권을 다시 클라이언트에게 되돌려 주고_ 먼저와 같은 상황이 된다

- 3. 추첨권 팽창(ticket inflation)

  - 프로세스는 일시적으로 자신이 소유한 추첨권의 수를 늘이거나 줄일 수 있다
  - 물론 서로 신뢰하지 않는 프로세스들이 상호 경쟁하는 시나리오에서는 의미가 없다. 하나의 욕심 많은 프로세스가 매우 많은 양의 추첨권을 자신에게 할당하고 컴퓨터를 장악할 수 있기 때문이다
  - 그러므로 화폐 팽창 기법은 프로세스들이 서로 신뢰할 때 유용하다
  - 어떤 프로세스가 더 많은 CPU 시간을 필요로 한다면, 시스템에게 이를 알리는 방법으로 다른 프로세스들과 통신하지 않고 혼자 추첨권의 가치를 상향 조정한다

### 구현

- 구현이 단순하다. 필요한 것은 1) 난수 발생기와 2) 프로세스들의 집합을 표현하는 자료 구조(예, 리스트), 3) 추첨권의 전체 개수 뿐이다

```c
// counter: 당첨자를 발견했는지 추적하는 데 사용됨
int counter = 0;
// winner: 0부터 총 추첨권의 수 사이의 임의의 값을 얻기 위해
// 난수 발생기를 호출함
int winner = getrandom(0, totaltickets);

// current: 작업 목록을 탐색하는 데 사용
node_t *current = head;
while (current) {
	counter = counter + current—>tickets;
	if (counter > winner)
		break; // 당첨자 발견
	current = current—>next;
}
// current는 당첨자를 가리킴: 당첨자가 실행될 수 있도록 준비
```

- e.g. 작업 리스트 : 프로세스 A(100) -> 프로세스 B(50) -> 프로세스 C(250) -> NULL
- 프로세스 리스트를 순회하면서 counter의 값이 winner의 값을 초과할 때까지 각 추첨권 개수를 counter에 더한다
- 값이 초과하게 되면 리스트의 현재 원소가 당첨자가 된다
- counter는 400(확실히 300보다 큼)으로 갱신되고 루프를 빠져 나오게 되고 current는 프로세스 C(당첨자)를 가리키게 된다
- 일반적으로 리스트를 내림차순으로 정렬하면 이 과정이 가장 효율적이 된다. 리스트를 정렬해 놓으면 검색 횟수가 최소화되는 것을 보장한다

### 예제

- CPU를 공유하는 두 개의 작업의 수행 시간을 살펴보자
- 각 프로세스는 같은 개수의 추첨권(100)을 가지고 있으며 동일한 실행 시간을 갖는다
- **우리는 두 작업을 거의 동시에 종료시키고자 한다.** 그러나 추첨 스케줄링의 무작위성 때문에 한 작업이 다른 작업보다 먼저 종료될 수 있다
- 이 차이를 정량화하기 위해, 간단한 불공정 지표(unfairness metric) 인 U를 정의한다

  - U = 첫 번째 작업 이 종료된 시간 / 두 번째 작업이 종료된 시간
  - 두 작업이 거의 동시에 종료하면 U는 1에 근접한다
  - 이 시나리오에서는 바로 그게 목표다. 완벽한 공정 스케줄러에서는 U = 1을 얻게 된다

  !["9-2"](9-2.png)

  - 그래프에서 보듯 작업 길이가 길지 않은 경우, 평균 불공정 정도는 심각하다. 작업이 충분한 기간 동안 실행되어야 추첨 스케줄러는 원하는 결과에 가까워진다

### 추첨권 배분 방식

- 추첨 스케줄링에서 아직 언급하지 않은 문제는 **추첨권을 작업에게 나누어주는 방식**이다
- 시스템 동작이 추첨권 할당 방식에 따라 크게 달라지기 때문에 상당히 어려운 문제이다
- 한 가지 접근 방식은 사용자가 가장 잘 알고 있다고 가정하는 것이다. 각 사용자에게 추첨권을 나누어 준 후 *사용자가 알아서 실행시키고자 하는 작업들에게 추첨권을 배분하는 것*이다
- 어떤 일을 해야 하는지 전혀 제시하지 않는다. 즉, 여전히 미해결 상태이다

### 왜 결정론적(Deterministic) 방법을 사용하지 않는가

- 무작위성을 이용하면 스케줄러를 단순하게 만들 수 있지만, **정확한 비율을 보장할 수 없다.** 작업의 길이가 짧을수록 보장할 수 없는 확률이 커진다
- 그래서 결정론적 공정 배분 스케줄러인 **보폭 스케줄링 (stride scheduling)**을 고안하였다
  - 시스템의 각 작업은 보폭을 가지고 있다
  - 보폭은 자신이 가지고 있는 추첨권 수에 반비례하는 값이다. 임의의 큰 값을 각자의 추첨권 개수로 나누어 보폭을 계산할 수 있다.
  - e.g. 10,000을 각자의 추첨권 개수로 나누면 각 작업의 보폭은 100(프로세스 A), 200(프로세스 B) 및 40(프로세스 C)이 된다
  - 프로세스가 실행될 때마다 **pass라는 값을 보폭만큼 증가시켜 얼마나 CPU를 사용하였는지를 추적**한다
- 스케줄러는 보폭과 pass 값을 사용하여 어느 프로세스를 실행시킬지 결정한다
- **가장 작은 pass 값을 가진 프로세스를 선택한다**

```c
curr = remove_min(queue);		// pass 값이 최소인 클라이언트로 선택
schedule(curr);					// 자원을 타임 퀀텀만큼 선택된 프로세스에게 할당
curr—>pass += curr—>stride;		// 다음 pass 값을 보폭 값을 이용하여 갱신
insert(queue, curr);			// curr를 다시 큐에 저장한다
```

- 세 작업(A, B, C), 각자의 보폭은 각각 100, 200, 40 이다
- 각자의 pass 값은 모두 0에서 시작한다. 처음에는 pass 값이 같기 때문에 아무 프로세스나 실행될 수 있다
- A를 선택했다고 가정하자. 타임 슬라이스만큼 실행되고 종료될 때 pass 값을 100으로 갱신한다
- 다음에 B가 실행되고 해당 pass 값이 200으로 갱신된다
- 마지막으로 C를 실행하고, pass 값은 40으로 갱신된다
- 다음으로 알고리즘은 가장 작은 pass 값을 가진 C를 선택하고, pass 값을 80으로 갱신한다
- 다시 C가 실행되고, pass 값은 120으로 갱신된다
- 이제 A가 실행되고 200으로 갱신된다
- 이후 C가 2번 더 실행되고 200으로 갱신된다

!["9-3"](../img/9-3.png)

- 그림에서 알 수 있듯이, C는 5번, A는 2번, B는 한번만 실행되었다. 이 횟수는 각자 가진 추첨권의 개수 250, 100, 50과 정확히 비례한다
- **추첨 스케줄링은 정해진 비율에 따라 확률적으로 CPU를 배분**한다
- **보폭 스케줄링은 각 스케줄링 주기마다 정확한 비율로 CPU를 배분**한다
- 보폭 스케줄링의 정확도를 고려할 때, 추첨 스케줄링을 왜 사용하는가?

  - 추첨 스케줄링은 보폭 스케줄링이 가지고 있지 않은 멋진 특성을 가지고 있다. 상태 정보가 필요 없다
  - 새로운 작업이 시스템에 도착했다고 상상해 보자. pass 값은 얼마가 되어야 하는가? 0으로 지정되어야 하는가? 그렇다면 CPU를 독점하게 될 것이다
  - 새 프로세스를 추가할 때, 새로운 프로세스가 가진 추첨권의 개수, 전체 추첨권의 개수만 갱신하고 스케줄한다
  - 이런 이유로 _추첨 스케줄링에서는 새 프로세스를 쉽게 추가할 수 있다_

### 리눅스 CFS (Completely Fair Scheduler)

- 현재 Linux는 기존과는 다른 방식으로 공정 배분 스케줄링을 구현하였다
- 이른바 Completely Fair Scheduler (또는 CFS 완전 공정 스케줄러)이다
- 이 스케줄러의 장점은 **효율성**과 **확장성**이다
- CFS는 스케줄링 결정을 매우 신속히 수행한다(효율성)
- 최근 연구결과에 따르면 스케줄러의 효율성이 전체 시스템 성능에 매우 중요한 영향을 갖는다고 한다. 매우 공격적으로 최적화된 스케줄링 알고리즘을 사용함에도 불구하고, 스케줄러가 전체 데이터센터 CPU 사용량의 5%를 차지한다는 것을 발견하였다. 스케줄링 오버헤드를 최대한 줄이는 것이 현대 스케줄러의 목표다

#### 기본 연산

- 대부분의 기존 스케줄러들은 **고정된 길이의 타임 슬라이스를 사용**한다. CFS는 이 점에서 기존 스케줄러와 다르다
- CFS는 모든 프로세스들에게 CPU를 공평하게 배분하는 것을 목표로 한다
- **virtual runtime(vruntime) 이라는 간단한 counting 기반 테크닉**을 사용한다.
  - _스케줄링시 CFS는 가장 낮은 vruntime을 가진 프로세스를 다음에 실행할 프로세스로 선택한다_
  - 프로세스가 실행되서, 스케줄러는 해당 프로세서의 vruntime 값을 누적시킨다
  - 가장 기본적인 경우, 각 프로세스의 vruntime은 실제 시간과 같은 속도로 증가한다
- vruntime은 가상 런타임(virtual runtime)으로, 실제 CPU 시간이 아니라 상대적인 시간을 나타냅니다
  - CFS에서 vruntime은 프로세스가 CPU를 사용한 런타임이 아니라, 프로세스가 CPU 시간을 얼마나 받을 것인지를 결정하는데 사용됩니다
  - vruntime은 상대적인 시간을 나타내기 위해 가중치에 의해 조정된다
- 스케줄러가 어느 시점에서 실행 중인 프로세스를 멈추고, 다음 프로세스를 실행할지 어떻게 결정할까?
  - CFS가 자주 실행되면, 각 프로세스가 작은 시간 간격으로 CPU를 사용하게 되어 공정성이 좋아진다. 하지만, 많은 문맥 교환이 발생하여 전체 시스템 성능에 악영향을 미칠 수 있다
  - 드물게 CFS가 실행되면, 문맥 교환 횟수가 감소하여 전체 시스템 성능은 향상되지만, 공정성은 악화된다
- CFS는 이 두 가지의 상충을 다양한 통제 변수들을 통해 관리한다
  - 1. `sched_latency`
    - 하나의 프로스세가 CPU를 사용한 후, 다음 번에 CPU를 사용할 수 있을 때까지의 최대 시간 간격을 나타낸다
    - 보통 sched_latency 값은 **48ms**이다
    - CFS는 이 값을 현재 실행 중인 프로세스의 개수(n)로 나눠서 프로세스의 타임 슬라이스를 결정한다
      !["9-4](9-4.png)
    - 4개의 프로세스가 실행 중이라 가정하자 (n = 4)
    - 프로세스당 타임 슬라이스의 길이는 12ms이다
    - CFS는 첫 번째 작업을 12ms (가상) 실행시간 동안 실행시킨다
    - 그 후 더 적은 vruntime 값을 가진 작업이 있는지 검사한다. 우리 예에서는 그러한 작업이 있으므로 CFS는 3개의 다른 작업 중에서 한 개를 선택하고, 선택된 작업으로 CPU를 전환한다
    - 4개 작업 (A,B,C,D)이 각각 2개 타임 슬라이스 만큼 실행되었다
    - 두개의 작업 (C,D)이 종료되면, 남은 두 개의 작업들이 24ms 만큼 실행된다
  - 2. `min_granularity`
    - 실행 중인 프로세스의 개수(n)이 많아지면, 타임 슬라이스의 크기가 매우 작아지고, 따라서 너무 많은 문맥 교환이 발생한다
    - 이 문제를 해결하기 위해, 최소 타임 슬라이스를 이용한다
    - 최소값은 보통 **6ms**로 설정되어 있다
    - 프로세스가 많아 프로세스당 타임 슬라이스의 길이가 6ms 미만이 된다면, min_granularity에 의해 타임 슬라이스를 6ms로 설정한다
    - 이렇게 되면, 48ms의 sched_latency는 보장이 어려워지지만 스케줄링은 효율적이 되고, 프로세스간에 CPU를 공평하게 배분하는 데에는 문제가 없다.
- CFS는 주기적으로 발생하는 타이머 인터럽트에 근간하여 작동한다. **즉, CFS는 특정 시간 간격으로만 스케줄링 결정을 내릴 수 있다**
  - 스케줄링 결정은 kernel space에서 실행된다
  - 타이머 인터럽트는 짧은 간격으로 발생하여 (e.g. 매 1 ms), CFS는 현재 작업의 타임 슬라이스 소진 여부를 판단한다
- CFS는 vruntime을 정확히 계산하고 이를 기반으로 스케줄링을 함으로써, 타이머 인터럽트의 주기가 타임 슬라이스와 정확히 맞아떨어지지 않을 경우에도, 궁극적으로 CPU를 공평하게 배분토록 한다

#### 가중치(Niceness)

##### 가중치 계산

- CFS는 사용자나 관리자가 프로세스의 우선 순위를 조정하여 다른 프로세스들 더 보다 많은 CPU 시간을 할당받게 할 수 있다
- 티켓이 아닌 *프로세스의 nice 레벨이라는 고전적 UNIX 메커니즘*을 사용한다
- nice는 0을 기본값으로 갖고 -20부터 19까지 가능하다
- nice가 양수값이면 낮은 우선순위를 의미하고 음수 값이면 높은 우선 순위를 의미한다

```c
static const int prio_to_weight [40] = {
/* -20 */	88761, 71755, 56483, 46273, 36291,
/* -15 */	29154, 23254, 18705, 14949, 11916,
/* -10 */	 9548,  7620,  6100,  4904,  3906,
/*  -5 */	 3121,  2501,  1991,  1586,  1277,
/*   0 */	 1024,   820,   655,   526,   423,
/*   5 */	  335,   272,   215,   172,   137,
/*  10 */	  110,    87,    70,    56,    45,
/*  15 */	   36,    29,    23,    18,    15,
};
```

- 이 가중치는 프로세스의 실질적인 타임 슬라이스를 계산하는데 사용된다
- 이제까지와는 달리 프로세스간의 우선순위 차이까지도 고려한다

!["9-5"](9-5.png)

- 특정 프로세스는 가중치 바율만큼 `sched_latency`의 타임 슬라이스를 할당받는다
- A는 중요한 작업이기 때문에 nice 값을 -5로 부여하여 높은 우선순위를 주었다. B는 중요하지 않아 nice 값을 기본값(0)으로 설정했다
- 가중치 표에서 weight A는 3121인데 비해, weight B는 1024가 된다
- 실제로 계산해보면, A의 타임 슬라이스가 `sched_latency`의 3/4(36ms), B의 타임 슬라이스는 `sched_latency`의 1/4(12ms)가 된다

##### vruntime 계산

- CFS에서 vruntime의 계산도 정교하게 만들 수 있다
- vruntime은 스케줄러가 다음 프로세스를 결정하는데 필요한 정보이다. vruntime이 가장 적은 프로세스를 문맥 교환 때 실행시킨다
- 실제 CPU 시간이 아니라 상대적인 시간을 나타냅니다
- **vruntime 에 실행시간 runtime 누적시키는 데 있어, 프로세스의 가중치를 반영한다**
- vruntime을 프로세스의 가중치에 반비례하여 계산한다

!["9-6"](9-6.png)

- 위에 예시에서는 A의 vruntime이 B의 vruntime에 비하여 1/3의 속도로 증가할 것이다
- `vruntime A = 0 + (3121 + 1024) / 3121 * 36 = 47.8`
- `vruntime B = 0 + (3121 + 1024) / 1024 * 12 = 48.5`
- 가중치 표의 장점은 nice 값의 차이가 유지되면, CPU 배분 비율도 유지된다는 것이다
- 실제로 CPU를 실행한 시간은 다르지만(36ms, 12ms) 상대적인 vruntime은 두 프로세스가 비슷한 값으로 계산된다. 따라서 CPU 배분 비율이 비슷해지는 효과가 있다
- 실제 CPU 실행 시간에는 가중치에 정비례하여 실행하지만, vruntime에는 가중치에 반비례하여 상대적으로 증가시킴으로써 CPU 배분 비율을 비슷하게 가져간다

##### Red-Black 트리의 활용

- CFS의 핵심은 알고리즘 효율성이다. 효율적 알고리즘을 이용하여 실행할 프로세스를 신속히 선정하는 것이 매우 중요하다
- 연결 리스트?
  - 단순해서 구현이 용이하다
  - 하지만 연결 리스트의 단점은 확장성에 있다. 링크드 리스트가 커질수록, 즉, 대기중인 프로세스의 개수와 리스트 검색시간이 선형 비례한다
- Red-Black 트리
  - 균형 트리의 한 종류
  - 단순 이진 트리는 최악의 경우 리스트와 비슷한 삽입 성능을 갖는다
  - 이와 달리, 균형 트리는 트리의 depth를 낮게 유지하기 위한 작업을 수행하며, 탐색 연산을 로그 시간의 복잡도로 수행한다
- _실행중이거나 또는 실행 가능한 프로세스들만_ 이 트리에 보관한다
  - 각 프로세스의 vruntime을 기준으로 순서대로 트리에 저장된다
  - 원소의 삽입, 삭제, 탐색의 경우 로그 시간이 소요된다
- 프로세스가 sleep 상태가 되면(I/O 완료 또는 네트워크 패킷 도착을 기다리는 경우), 프로세스는 트리에서 제거되고 다른 곳에 보관된다

##### I/O와 잠자는 프로세스 다루기

- 또 해결해야할 사항은 장기간 잠자고 있는 프로세스의 처리이다
- 프로세스 A는 계속 실행 중이고, 프로세스 B는 장시간(10초 이상) 잠자고 있었다고 가정하자
- _B가 깨어나면, B의 vruntime은 A보다 10초 뒤처져 있을 것이다_
- 이렇게 되면 B는 다음 10초 동안 CPU를 독점하게 될 것이다. A는 B가 깨어난 후 10초간 CPU를 할당받지 못하고, 기아상태에 빠지게 된다
- CFS는 이를 해결하기 위해, 작업이 깨어날 때, vruntime을 적절히 재설정한다
  - 구체적으로, CFS는 깨어난 작업의 vruntime을 트리에서 찾을 수 있는 가장 작은 값으로 설정한다
- CFS는 큰 오버헤드 없이 기아 현상을 방지한다
- 여전히 짧은 시간 간격으로 자주 잠자기에 들어가는 작업들은 CPU 배분에 있어서 손해를 보게된다

### 요약

- 비례 배분 스케줄링(공정성 배분 스케줄링)을 소개하고, 1) 추첨권 스케줄링, 2) 보폭 스케줄링, 그리고 3) 리눅스의 CFS라는 세 가지 구현 방식에 대해 간단하게 논의하였다
- 추첨권 스케줄링은 무작위성 (randomness)을 사용한다
  - 장) 스케줄러를 단순하게 만들 수 있다
  - 단) 작업의 길이가 짧을수록 정확한 비율을 보장할 수 없는 확률이 커진다
- 보폭 스케줄링은 같은 목적을 결정적 방법으로 달성한다
  - 장) 보폭(추첨권의 반비례 값)을 이용하여 각 스케줄링 주기마다 정확한 비율로 CPU를 배분한다
  - 단) 새로운 작업이 시스템에 도착했을 때, 적절하게 초기 pass 값을 설정해주지 않으면 CPU 독점하는 문제가 발생한다. 이러한 문제들은 스케줄러 동작을 복잡하게 만든다
- 유일한 실제 스케줄러인 CFS는 동적 타임 슬라이스를 가진 가중치 라운드 로빈 기법 같지만, 부하에 잘 견디도록 확장성과 성능을 보장하는 스케줄러다
  - 장) 효율성(스케줄링 결정을 매우 신속히 수행한다 : Red-Black 트리), 확장성(새로운 프로세스 / 입출력 프로세스의 처리)
  - 단) 짧은 시간 간격으로 자주 잠자기에 들어가는 작업들은 CPU 배분에 있어서 손해 등...
- 우리가 아는 바로는, CFS는 현존하는 공정성 배분 스케줄러 중 가장 널리 쓰인다

- 모든 경우에서 다 좋은 성능을 보이는 스케쥴러는 존재하지 않는다
  - 공정 배분 스케줄러가 입출력 스케줄러와 서로 맞물리면, CPU 스케줄러가 원하는 식으로 CPU를 할당할 수 없다
  - 자주 I/O를 수행하는 작업들은 CPU를 원하는 데로 배분받지 못할 수 있다
- 티켓이나 우선순위를 얼만큼씩 할당해야하는가에 대한 보다 *근본적인 문제*다. 이 문제는 여전히 미해결 상태다
- 다행히 배분 문제가 그리 중요하지 않은 경우가 많다. 이 경우들에서는 비례 배분 스케줄러들이 유용하게 사용된다
  - 예를 들어, 가상화 데이터 센터 (혹은 클라우드)에서 윈도우즈 가상 머신에 CPU 사이클의 1/4을 할당하고 나머지는 리눅스 시스템에 할당 하고 싶은 경우라면 비례 배분이 간단하고 효과적이다

### 숙제

- 추첨권 스케줄러의 동작 방식
